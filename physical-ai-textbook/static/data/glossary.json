[
  {
    "term": "Action",
    "aliases": ["ROS Action", "Action Server"],
    "definition": "A ROS 2 communication pattern for long-running tasks that provides feedback during execution and allows cancellation. Actions combine request-response (like services) with ongoing feedback updates.",
    "relatedChapters": ["Module 1: Actions", "Multi-Node Systems"],
    "externalLinks": [
      { "label": "ROS 2 Actions Documentation", "url": "https://docs.ros.org/en/humble/Tutorials/Intermediate/Writing-an-Action-Server-Client/Py.html" }
    ]
  },
  {
    "term": "Actuator",
    "aliases": ["Motor", "Servo"],
    "definition": "A mechanical device that converts electrical signals into physical motion. Common types include DC motors, servo motors, and stepper motors used to control robot joints and movements.",
    "relatedChapters": ["Module 2: Robot Modeling"],
    "externalLinks": [
      { "label": "Actuator Types Overview", "url": "https://en.wikipedia.org/wiki/Actuator" }
    ]
  },
  {
    "term": "Adaptive Monte Carlo Localization",
    "aliases": ["AMCL", "MCL"],
    "definition": "A probabilistic localization algorithm that uses particle filters to estimate a robot's position within a known map. It adapts the number of particles based on localization confidence.",
    "relatedChapters": ["Module 2: Navigation"],
    "externalLinks": [
      { "label": "AMCL ROS Package", "url": "https://navigation.ros.org/configuration/packages/configuring-amcl.html" }
    ]
  },
  {
    "term": "AGI",
    "aliases": ["Artificial General Intelligence"],
    "definition": "A hypothetical form of artificial intelligence that possesses the ability to understand, learn, and apply knowledge across a wide range of tasks at a human-like level.",
    "relatedChapters": ["Module 4: VLA Models"],
    "externalLinks": []
  },
  {
    "term": "Bag File",
    "aliases": ["ROSbag", "ROS Bag"],
    "definition": "A file format used in ROS to record and playback topic data. Useful for debugging, testing, and creating reproducible scenarios without re-running live systems.",
    "relatedChapters": ["Module 1: ROS 2 Fundamentals"],
    "externalLinks": [
      { "label": "ROS 2 Bag Documentation", "url": "https://docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Recording-And-Playing-Back-Data/Recording-And-Playing-Back-Data.html" }
    ]
  },
  {
    "term": "Base Link",
    "aliases": ["base_link", "Robot Base"],
    "definition": "The primary coordinate frame attached to the robot's base, serving as the reference point for all other frames in the robot's transformation tree (TF tree).",
    "relatedChapters": ["Module 1: ROS 2 Fundamentals", "Module 2: URDF Modeling"],
    "externalLinks": []
  },
  {
    "term": "BERT",
    "aliases": ["Bidirectional Encoder Representations from Transformers"],
    "definition": "A transformer-based language model developed by Google that uses bidirectional training to understand context from both left and right of a word in sentences.",
    "relatedChapters": ["Module 4: VLA Models"],
    "externalLinks": [
      { "label": "BERT Paper", "url": "https://arxiv.org/abs/1810.04805" }
    ]
  },
  {
    "term": "Camera Intrinsics",
    "aliases": ["Calibration Matrix", "K Matrix"],
    "definition": "Parameters describing a camera's internal characteristics including focal length, optical center, and lens distortion. Essential for 3D reconstruction and computer vision tasks.",
    "relatedChapters": ["Module 3: Perception Pipeline"],
    "externalLinks": []
  },
  {
    "term": "Capstone Project",
    "aliases": ["Final Project"],
    "definition": "The culminating project integrating all four course modules (ROS 2, Digital Twin, Isaac Sim, VLA) into a complete autonomous humanoid system capable of natural language control.",
    "relatedChapters": ["Week 13: Capstone Integration"],
    "externalLinks": []
  },
  {
    "term": "Cartesian Space",
    "aliases": ["Task Space", "Operational Space"],
    "definition": "The 3D workspace defined by X, Y, Z coordinates and orientation (roll, pitch, yaw) where the robot end-effector operates, as opposed to joint space.",
    "relatedChapters": ["Module 2: Manipulation"],
    "externalLinks": []
  },
  {
    "term": "CLIP",
    "aliases": ["Contrastive Language-Image Pretraining"],
    "definition": "An OpenAI model that learns visual concepts from natural language supervision, enabling zero-shot image classification and vision-language understanding.",
    "relatedChapters": ["Module 4: VLA Models"],
    "externalLinks": [
      { "label": "CLIP Paper", "url": "https://arxiv.org/abs/2103.00020" }
    ]
  },
  {
    "term": "Colcon",
    "aliases": ["Colcon Build System"],
    "definition": "The build system used in ROS 2 for compiling packages. It supports multiple build types (CMake, Python setuptools, ament) and parallel builds for faster compilation.",
    "relatedChapters": ["Module 1: ROS 2 Fundamentals"],
    "externalLinks": [
      { "label": "Colcon Tutorial", "url": "https://docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Colcon-Tutorial.html" }
    ]
  },
  {
    "term": "Collision Detection",
    "aliases": ["Collision Checking"],
    "definition": "The process of determining whether objects in a simulated or real environment intersect or come into contact. Critical for motion planning and safety.",
    "relatedChapters": ["Module 2: Gazebo Simulation", "Module 3: Isaac Sim"],
    "externalLinks": []
  },
  {
    "term": "Costmap",
    "aliases": ["Occupancy Grid", "Navigation Costmap"],
    "definition": "A 2D grid representation of the environment where each cell has a cost value indicating traversability. Used by navigation algorithms to plan collision-free paths.",
    "relatedChapters": ["Module 2: Navigation"],
    "externalLinks": []
  },
  {
    "term": "CUDA",
    "aliases": ["Compute Unified Device Architecture"],
    "definition": "NVIDIA's parallel computing platform and API that allows developers to use GPUs for general-purpose processing, essential for deep learning and physics simulation.",
    "relatedChapters": ["Setup: Hardware Requirements", "Module 3: Isaac Sim"],
    "externalLinks": [
      { "label": "CUDA Toolkit", "url": "https://developer.nvidia.com/cuda-toolkit" }
    ]
  },
  {
    "term": "DDS",
    "aliases": ["Data Distribution Service", "RTPS"],
    "definition": "The middleware protocol used by ROS 2 for inter-process communication. Provides real-time publish-subscribe messaging with quality-of-service guarantees.",
    "relatedChapters": ["Module 1: ROS 2 Architecture"],
    "externalLinks": [
      { "label": "DDS Specification", "url": "https://www.omg.org/spec/DDS/" }
    ]
  },
  {
    "term": "Degrees of Freedom",
    "aliases": ["DOF"],
    "definition": "The number of independent parameters that define a robot's configuration. A 6-DOF manipulator can position and orient its end-effector freely in 3D space.",
    "relatedChapters": ["Module 2: Kinematics"],
    "externalLinks": []
  },
  {
    "term": "Digital Twin",
    "aliases": ["Virtual Twin", "Simulation Model"],
    "definition": "A virtual replica of a physical system that mimics its behavior, appearance, and dynamics. Used for testing, training, and validation before deploying to real hardware.",
    "relatedChapters": ["Module 2: Digital Twin Simulation"],
    "externalLinks": []
  },
  {
    "term": "Direct Kinematics",
    "aliases": ["Forward Kinematics", "FK"],
    "definition": "The process of calculating the end-effector position and orientation given joint angles. The opposite of inverse kinematics.",
    "relatedChapters": ["Module 2: Kinematics"],
    "externalLinks": []
  },
  {
    "term": "Domain Randomization",
    "aliases": ["Sim-to-Real Transfer"],
    "definition": "A technique for training models in simulation with randomized parameters (lighting, textures, physics) to improve transferability to real-world environments.",
    "relatedChapters": ["Module 2: Unity ML-Agents"],
    "externalLinks": []
  },
  {
    "term": "Embodied AI",
    "aliases": ["Physical AI", "Embodied Intelligence"],
    "definition": "AI systems that interact with the physical world through sensors and actuators, as opposed to purely virtual AI. Includes robots, autonomous vehicles, and smart devices.",
    "relatedChapters": ["Introduction"],
    "externalLinks": []
  },
  {
    "term": "End Effector",
    "aliases": ["Gripper", "Tool"],
    "definition": "The device at the end of a robotic arm that interacts with the environment, such as a gripper, suction cup, or welding torch.",
    "relatedChapters": ["Module 2: Manipulation"],
    "externalLinks": []
  },
  {
    "term": "Extended Kalman Filter",
    "aliases": ["EKF"],
    "definition": "A nonlinear version of the Kalman filter used for state estimation by linearizing around the current estimate. Commonly used for sensor fusion and robot localization.",
    "relatedChapters": ["Module 3: Sensor Fusion"],
    "externalLinks": []
  },
  {
    "term": "Fuse.js",
    "aliases": ["Fuzzy Search"],
    "definition": "A JavaScript library for lightweight fuzzy-search functionality, used in this textbook for the glossary search component with approximate string matching.",
    "relatedChapters": ["Setup: Glossary Search"],
    "externalLinks": [
      { "label": "Fuse.js Documentation", "url": "https://fusejs.io/" }
    ]
  },
  {
    "term": "Gazebo",
    "aliases": ["Gazebo Simulator", "Ignition Gazebo"],
    "definition": "An open-source 3D robot simulator that provides physics simulation, sensor models, and integration with ROS. Used for testing algorithms before hardware deployment.",
    "relatedChapters": ["Module 2: Digital Twin Simulation"],
    "externalLinks": [
      { "label": "Gazebo Website", "url": "https://gazebosim.org/" }
    ]
  },
  {
    "term": "Grasp Planning",
    "aliases": ["Grasping", "Grasp Synthesis"],
    "definition": "The process of determining optimal gripper poses and trajectories to securely grasp objects. Involves force analysis, contact modeling, and stability evaluation.",
    "relatedChapters": ["Module 3: Manipulation"],
    "externalLinks": []
  },
  {
    "term": "Humanoid Robot",
    "aliases": ["Anthropomorphic Robot", "Android"],
    "definition": "A robot with a body shape resembling the human form, typically including a torso, head, two arms, and two legs. Examples include Atlas, Optimus, and ASIMO.",
    "relatedChapters": ["Module 4: Humanoid Integration"],
    "externalLinks": []
  },
  {
    "term": "IMU",
    "aliases": ["Inertial Measurement Unit"],
    "definition": "A sensor that measures linear acceleration and angular velocity using accelerometers and gyroscopes. Essential for robot orientation and motion estimation.",
    "relatedChapters": ["Module 1: Sensors", "Module 3: Sensor Fusion"],
    "externalLinks": []
  },
  {
    "term": "Inverse Kinematics",
    "aliases": ["IK"],
    "definition": "The process of calculating joint angles required to achieve a desired end-effector position and orientation. Often has multiple solutions or no solution.",
    "relatedChapters": ["Module 2: Kinematics", "Module 3: Manipulation"],
    "externalLinks": []
  },
  {
    "term": "Isaac Sim",
    "aliases": ["NVIDIA Isaac Sim", "Omniverse Isaac"],
    "definition": "NVIDIA's GPU-accelerated robotics simulator built on Omniverse, providing photorealistic rendering, accurate physics, and synthetic data generation for perception training.",
    "relatedChapters": ["Module 3: NVIDIA Isaac Sim"],
    "externalLinks": [
      { "label": "Isaac Sim Documentation", "url": "https://docs.omniverse.nvidia.com/isaacsim/latest/" }
    ]
  },
  {
    "term": "Jetson",
    "aliases": ["NVIDIA Jetson", "Jetson Orin"],
    "definition": "NVIDIA's line of embedded computing boards designed for edge AI applications. The Jetson Orin Nano is recommended for this course's edge deployment option.",
    "relatedChapters": ["Setup: Jetson Orin Nano"],
    "externalLinks": [
      { "label": "Jetson Products", "url": "https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/" }
    ]
  },
  {
    "term": "Joint Space",
    "aliases": ["Configuration Space"],
    "definition": "The space defined by robot joint angles (q1, q2, ... qn), as opposed to Cartesian space. Motion planning often occurs in joint space.",
    "relatedChapters": ["Module 2: Kinematics"],
    "externalLinks": []
  },
  {
    "term": "Kalman Filter",
    "aliases": ["KF", "Linear Quadratic Estimation"],
    "definition": "An optimal state estimation algorithm that combines predictions from a model with noisy sensor measurements to estimate system state with minimal error variance.",
    "relatedChapters": ["Module 3: Sensor Fusion"],
    "externalLinks": []
  },
  {
    "term": "Lidar",
    "aliases": ["LiDAR", "Laser Scanner"],
    "definition": "A sensor that measures distance by illuminating targets with laser light and measuring reflections. Produces 2D or 3D point clouds for mapping and obstacle detection.",
    "relatedChapters": ["Module 3: Perception Pipeline"],
    "externalLinks": []
  },
  {
    "term": "LLM",
    "aliases": ["Large Language Model"],
    "definition": "A deep learning model trained on vast text corpora to understand and generate human language. Examples include GPT-4, Claude, and PaLM used in VLA architectures.",
    "relatedChapters": ["Module 4: VLA Models"],
    "externalLinks": []
  },
  {
    "term": "Localization",
    "aliases": ["Robot Localization"],
    "definition": "The process of determining a robot's position and orientation within a known map or environment using sensor data and probabilistic algorithms.",
    "relatedChapters": ["Module 2: Navigation", "Module 3: Sensor Fusion"],
    "externalLinks": []
  },
  {
    "term": "Message",
    "aliases": ["ROS Message", "Topic Message"],
    "definition": "A data structure in ROS that defines the format of information exchanged between nodes via topics. Defined in .msg files with primitive and composite types.",
    "relatedChapters": ["Module 1: Nodes and Topics"],
    "externalLinks": []
  },
  {
    "term": "Motion Planning",
    "aliases": ["Path Planning", "Trajectory Planning"],
    "definition": "The process of finding a collision-free path for a robot to move from a start to goal configuration. Algorithms include RRT, PRM, and A*.",
    "relatedChapters": ["Module 2: Navigation", "Module 3: Manipulation"],
    "externalLinks": []
  },
  {
    "term": "MoveIt",
    "aliases": ["MoveIt2", "Motion Planning Framework"],
    "definition": "An open-source motion planning framework for ROS that provides inverse kinematics, collision checking, and manipulation primitives for robot arms.",
    "relatedChapters": ["Module 2: Manipulation"],
    "externalLinks": [
      { "label": "MoveIt 2 Documentation", "url": "https://moveit.picknik.ai/main/index.html" }
    ]
  },
  {
    "term": "Navigation2",
    "aliases": ["Nav2", "ROS 2 Navigation"],
    "definition": "The official ROS 2 navigation stack providing mobile robot navigation capabilities including localization, path planning, and obstacle avoidance.",
    "relatedChapters": ["Module 2: Navigation"],
    "externalLinks": [
      { "label": "Navigation2 Docs", "url": "https://navigation.ros.org/" }
    ]
  },
  {
    "term": "Node",
    "aliases": ["ROS Node", "Computational Node"],
    "definition": "An executable process in ROS that performs computation. Nodes communicate via topics, services, and actions to form distributed robotic systems.",
    "relatedChapters": ["Module 1: ROS 2 Fundamentals"],
    "externalLinks": []
  },
  {
    "term": "Occupancy Grid",
    "aliases": ["Grid Map"],
    "definition": "A 2D probabilistic map representation where each cell indicates the probability that the space is occupied by an obstacle. Used for navigation and SLAM.",
    "relatedChapters": ["Module 2: Mapping"],
    "externalLinks": []
  },
  {
    "term": "Odometry",
    "aliases": ["Odom", "Wheel Odometry"],
    "definition": "The estimation of a robot's change in position over time using sensor data such as wheel encoders, IMU, or visual features. Accumulates error over distance.",
    "relatedChapters": ["Module 1: Sensors", "Module 2: Localization"],
    "externalLinks": []
  },
  {
    "term": "Omniverse",
    "aliases": ["NVIDIA Omniverse"],
    "definition": "NVIDIA's platform for 3D simulation and collaboration built on Universal Scene Description (USD). Isaac Sim is built on top of Omniverse.",
    "relatedChapters": ["Module 3: Isaac Sim Setup"],
    "externalLinks": [
      { "label": "Omniverse Platform", "url": "https://www.nvidia.com/en-us/omniverse/" }
    ]
  },
  {
    "term": "Particle Filter",
    "aliases": ["Sequential Monte Carlo", "SMC"],
    "definition": "A probabilistic localization algorithm that represents the robot's pose distribution with a set of weighted particles. Used in AMCL for localization.",
    "relatedChapters": ["Module 2: Localization"],
    "externalLinks": []
  },
  {
    "term": "PhysX",
    "aliases": ["NVIDIA PhysX"],
    "definition": "NVIDIA's real-time physics engine used in Isaac Sim for accurate rigid body dynamics, collision detection, and contact simulation with GPU acceleration.",
    "relatedChapters": ["Module 3: Isaac Sim"],
    "externalLinks": []
  },
  {
    "term": "Point Cloud",
    "aliases": ["3D Point Cloud", "PCL"],
    "definition": "A collection of 3D points representing object surfaces or environments, typically captured by lidar or depth cameras. Used for object detection and mapping.",
    "relatedChapters": ["Module 3: Perception Pipeline"],
    "externalLinks": []
  },
  {
    "term": "Pose",
    "aliases": ["6D Pose", "Position and Orientation"],
    "definition": "The combination of a 3D position (x, y, z) and 3D orientation (roll, pitch, yaw or quaternion) that fully describes an object's location in space.",
    "relatedChapters": ["Module 1: TF2", "Module 3: Pose Estimation"],
    "externalLinks": []
  },
  {
    "term": "Publish-Subscribe",
    "aliases": ["Pub-Sub", "Topic Communication"],
    "definition": "A messaging pattern where publishers send data to topics without knowing subscribers, and subscribers receive data without knowing publishers. Core ROS 2 pattern.",
    "relatedChapters": ["Module 1: Nodes and Topics"],
    "externalLinks": []
  },
  {
    "term": "QoS",
    "aliases": ["Quality of Service"],
    "definition": "Policies in ROS 2 DDS that control message reliability, durability, and history. Different QoS profiles optimize for real-time vs reliable communication.",
    "relatedChapters": ["Module 1: Advanced Topics"],
    "externalLinks": [
      { "label": "ROS 2 QoS Docs", "url": "https://docs.ros.org/en/humble/Concepts/About-Quality-of-Service-Settings.html" }
    ]
  },
  {
    "term": "Quaternion",
    "aliases": ["Unit Quaternion"],
    "definition": "A mathematical representation of 3D orientation using four numbers (w, x, y, z) that avoids gimbal lock. Preferred over Euler angles in robotics.",
    "relatedChapters": ["Module 1: TF2", "Module 2: Kinematics"],
    "externalLinks": []
  },
  {
    "term": "Ray Tracing",
    "aliases": ["Path Tracing", "RTX"],
    "definition": "A rendering technique that simulates light propagation for photorealistic images. Isaac Sim uses GPU ray tracing for sensor simulation and synthetic data.",
    "relatedChapters": ["Module 3: Isaac Sim"],
    "externalLinks": []
  },
  {
    "term": "RGB-D Camera",
    "aliases": ["Depth Camera", "RGBD Sensor"],
    "definition": "A camera that captures both color (RGB) and depth information for each pixel, enabling 3D reconstruction. Examples include Intel RealSense and Azure Kinect.",
    "relatedChapters": ["Module 3: Perception"],
    "externalLinks": []
  },
  {
    "term": "Robot Operating System",
    "aliases": ["ROS", "ROS 2"],
    "definition": "An open-source framework for robot software development providing communication infrastructure, hardware abstraction, and package management. ROS 2 is the current version.",
    "relatedChapters": ["Module 1: ROS 2 Fundamentals"],
    "externalLinks": [
      { "label": "ROS 2 Official Site", "url": "https://docs.ros.org/en/humble/" }
    ]
  },
  {
    "term": "RRT",
    "aliases": ["Rapidly-Exploring Random Tree"],
    "definition": "A sampling-based motion planning algorithm that builds a tree of random configurations to find paths in high-dimensional spaces. Fast but produces jagged paths.",
    "relatedChapters": ["Module 2: Path Planning"],
    "externalLinks": []
  },
  {
    "term": "RViz",
    "aliases": ["RViz2", "ROS Visualization"],
    "definition": "A 3D visualization tool for ROS that displays sensor data, robot models, transforms, and planned paths. Essential for debugging and monitoring robots.",
    "relatedChapters": ["Module 1: ROS 2 Tools"],
    "externalLinks": []
  },
  {
    "term": "Sensor Fusion",
    "aliases": ["Multi-Sensor Integration"],
    "definition": "The process of combining data from multiple sensors (IMU, GPS, lidar, camera) to produce more accurate and reliable state estimates than any single sensor.",
    "relatedChapters": ["Module 3: Sensor Fusion"],
    "externalLinks": []
  },
  {
    "term": "Service",
    "aliases": ["ROS Service", "Request-Response"],
    "definition": "A ROS 2 communication pattern for synchronous request-response interactions. A client sends a request and blocks until receiving a response from the server.",
    "relatedChapters": ["Module 1: Services"],
    "externalLinks": []
  },
  {
    "term": "SLAM",
    "aliases": ["Simultaneous Localization and Mapping"],
    "definition": "The problem of building a map of an unknown environment while simultaneously localizing the robot within that map. Fundamental problem in mobile robotics.",
    "relatedChapters": ["Module 2: Mapping and Localization"],
    "externalLinks": []
  },
  {
    "term": "Synthetic Data",
    "aliases": ["Simulated Data"],
    "definition": "Artificially generated training data from simulation rather than real-world collection. Isaac Sim excels at generating labeled synthetic images for perception training.",
    "relatedChapters": ["Module 3: Isaac Sim", "Module 4: VLA Training"],
    "externalLinks": []
  },
  {
    "term": "TF2",
    "aliases": ["Transform Library", "tf2_ros"],
    "definition": "ROS 2's coordinate frame transformation system that manages the relationships between different reference frames in a robot system over time.",
    "relatedChapters": ["Module 1: ROS 2 Fundamentals"],
    "externalLinks": [
      { "label": "TF2 Tutorials", "url": "https://docs.ros.org/en/humble/Tutorials/Intermediate/Tf2/Tf2-Main.html" }
    ]
  },
  {
    "term": "Topic",
    "aliases": ["ROS Topic"],
    "definition": "A named bus over which nodes exchange messages in a publish-subscribe pattern. Topics enable asynchronous, many-to-many communication in ROS 2.",
    "relatedChapters": ["Module 1: Nodes and Topics"],
    "externalLinks": []
  },
  {
    "term": "Transformer",
    "aliases": ["Attention Mechanism"],
    "definition": "A deep learning architecture using self-attention mechanisms, foundational to modern language models (GPT, BERT) and increasingly used in vision and robotics.",
    "relatedChapters": ["Module 4: VLA Architecture"],
    "externalLinks": [
      { "label": "Attention Is All You Need", "url": "https://arxiv.org/abs/1706.03762" }
    ]
  },
  {
    "term": "Unity ML-Agents",
    "aliases": ["ML-Agents", "Unity Machine Learning"],
    "definition": "An open-source toolkit for training intelligent agents in Unity environments using reinforcement learning, imitation learning, and neuroevolution.",
    "relatedChapters": ["Module 2: Digital Twin Simulation"],
    "externalLinks": [
      { "label": "ML-Agents GitHub", "url": "https://github.com/Unity-Technologies/ml-agents" }
    ]
  },
  {
    "term": "URDF",
    "aliases": ["Unified Robot Description Format"],
    "definition": "An XML format for describing robot models including links, joints, visual meshes, collision geometry, and inertial properties. Standard for ROS robots.",
    "relatedChapters": ["Module 2: Robot Modeling"],
    "externalLinks": [
      { "label": "URDF Tutorials", "url": "https://docs.ros.org/en/humble/Tutorials/Intermediate/URDF/URDF-Main.html" }
    ]
  },
  {
    "term": "Vision-Language-Action",
    "aliases": ["VLA", "VLA Model", "Embodied AI Model"],
    "definition": "A class of models that integrate vision, language understanding, and action prediction to enable robots to follow natural language commands for manipulation tasks.",
    "relatedChapters": ["Module 4: VLA Models"],
    "externalLinks": []
  },
  {
    "term": "Visual Servoing",
    "aliases": ["Vision-Based Control"],
    "definition": "A control technique that uses visual feedback from cameras to guide robot motion, enabling tasks like object tracking and precision manipulation.",
    "relatedChapters": ["Module 3: Vision-Based Control"],
    "externalLinks": []
  },
  {
    "term": "VRAM",
    "aliases": ["Video RAM", "GPU Memory"],
    "definition": "Memory dedicated to the graphics card for storing textures, framebuffers, and computation data. Isaac Sim requires 12GB+ VRAM for high-fidelity simulation.",
    "relatedChapters": ["Setup: Hardware Requirements"],
    "externalLinks": []
  },
  {
    "term": "Workspace",
    "aliases": ["ROS Workspace", "Colcon Workspace"],
    "definition": "A directory structure containing ROS 2 packages that are built together. Consists of src/ (source code), build/ (build artifacts), install/ (binaries), and log/ folders.",
    "relatedChapters": ["Module 1: ROS 2 Setup"],
    "externalLinks": []
  },
  {
    "term": "YOLO",
    "aliases": ["You Only Look Once", "YOLOv8"],
    "definition": "A family of real-time object detection models that process images in a single forward pass. YOLOv8 is commonly used for robotic perception tasks.",
    "relatedChapters": ["Module 3: Object Detection"],
    "externalLinks": [
      { "label": "YOLOv8 Documentation", "url": "https://docs.ultralytics.com/" }
    ]
  },
  {
    "term": "Zero-Shot Learning",
    "aliases": ["ZSL"],
    "definition": "The ability of a model to recognize or perform tasks it wasn't explicitly trained on by leveraging semantic knowledge. VLA models exhibit zero-shot manipulation capabilities.",
    "relatedChapters": ["Module 4: VLA Models"],
    "externalLinks": []
  }
]
