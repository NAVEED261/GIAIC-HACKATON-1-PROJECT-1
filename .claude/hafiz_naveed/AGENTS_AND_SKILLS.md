# ğŸ¤– COMPLETE AGENTS GUIDE - DETAILED BREAKDOWN

## ğŸ“Š TOTAL AGENTS: 16

**GROUP 1: Domain Experts (5)**
**GROUP 2: Workflow Commands (11)**

---

# ğŸ”´ GROUP 1: DOMAIN-SPECIFIC AGENTS (5)

---

## **AGENT #1: DOCUSAURUS CHATBOT AGENT**

### **Command:** `/docusaurus-chatbot-agent`

### **Skills (Roman Urdu):**
- React 18 + TypeScript - React library mein components banate ho
- Docusaurus v3 integration - Docusaurus website mein chatbot add karta hai
- Text selection API - User jab text select kare to us pe action le sakte ho
- Fetch API - Frontend se backend ko request bhejna
- CSS modules - Component-specific styling (CSS ko isolated rakhna)
- Dark/light mode - Raat ka mode aur din ka mode
- Mobile responsive design - Chhoti screen aur badi screen dono mein chalega
- State management - React hooks se data manage karna (useState, useEffect)
- Error handling - Jab error aye to kya show karna

### **PRACTICAL USE CASE:**

**User Query:** "Yaar, mara chatbot widget bahut slow open hota hai aur dark mode bhi chahiye"

### **Step-by-Step Process:**

```
STEP 1: USER QUERY
â”œâ”€ User: "Chatbot widget ko fast karna hai aur dark mode add karna hai"

STEP 2: AGENT ACTIVATION
â”œâ”€ /docusaurus-chatbot-agent activate ho jaata hai

STEP 3: CODE ANALYSIS
â”œâ”€ Agent: "Aapka ChatWidget.tsx file dekh raha hoon..."
â”œâ”€ Agent: "Isme useState aur useEffect ho rahe hain"
â”œâ”€ Agent: "Opening animation 500ms ka hai"
â”œâ”€ Agent: "Dark mode abhi nahi hai"

STEP 4: PERFORMANCE CHECK
â”œâ”€ Agent: "Performance issues:"
â”œâ”€   - API call har bar naye kiye jaa rahe hain (caching nahi ho)
â”œâ”€   - CSS animation heavy hai
â”œâ”€   - Message rendering optimize nahi hai

STEP 5: SOLUTIONS SUGGEST
â”œâ”€ Agent: "Theek hai, maine 3 solutions diye hain:"
â”œâ”€   1. useState mein useMemo add karo
â”œâ”€   2. CSS animation ko hardware-accelerated banao
â”œâ”€   3. Dark mode ke liye CSS variables use karo

STEP 6: CODE EXAMPLES DENA
â”œâ”€ Agent: "Yeh raha updated ChatWidget.tsx code:"
â”œâ”€
â”œâ”€ ```typescript
â”œâ”€ import React, { useState, useMemo } from 'react';
â”œâ”€ import styles from './styles.module.css';
â”œâ”€
â”œâ”€ const ChatWidget = () => {
â”œâ”€   const [isDarkMode, setIsDarkMode] = useState(false);
â”œâ”€   const [isOpen, setIsOpen] = useState(false);
â”œâ”€
â”œâ”€   // Memoized messages - performance boost
â”œâ”€   const memoizedMessages = useMemo(() => messages, [messages]);
â”œâ”€
â”œâ”€   return (
â”œâ”€     <div className={`${styles.widget} ${isDarkMode ? styles.dark : ''}`}>
â”œâ”€       {/* Dark mode toggle */}
â”œâ”€       <button onClick={() => setIsDarkMode(!isDarkMode)}>
â”œâ”€         {isDarkMode ? 'â˜€ï¸' : 'ğŸŒ™'}
â”œâ”€       </button>
â”œâ”€
â”œâ”€       {/* Optimized rendering */}
â”œâ”€       {memoizedMessages.map(msg => (
â”œâ”€         <div key={msg.id} className={styles.message}>
â”œâ”€           {msg.content}
â”œâ”€         </div>
â”œâ”€       ))}
â”œâ”€     </div>
â”œâ”€   );
â”œâ”€ };
â”œâ”€ ```

STEP 7: CSS UPDATES
â”œâ”€ Agent: "Yeh raha optimized CSS:"
â”œâ”€
â”œâ”€ `.widget {
â”œâ”€   animation: slideIn 300ms ease-out; /* Fast animation */
â”œâ”€   --bg-color: #fff;
â”œâ”€   --text-color: #000;
â”œâ”€   background-color: var(--bg-color);
â”œâ”€   color: var(--text-color);
â”œâ”€ }
â”œâ”€
â”œâ”€ .widget.dark {
â”œâ”€   --bg-color: #1a1a1a;
â”œâ”€   --text-color: #fff;
â”œâ”€ }
â”œâ”€
â”œâ”€ @keyframes slideIn {
â”œâ”€   from { transform: translateY(10px); opacity: 0; }
â”œâ”€   to { transform: translateY(0); opacity: 1; }
â”œâ”€ }`

STEP 8: TESTING GUIDE
â”œâ”€ Agent: "Testing steps:"
â”œâ”€   1. Browser DevTools > Lighthouse > Performance check karo
â”œâ”€   2. Dark mode toggle test karo (kaam karega ab)
â”œâ”€   3. Mobile responsive test karo (375px width mein)
â”œâ”€   4. Backend se real query test karo

STEP 9: FINAL CHECKLIST
â”œâ”€ Agent: "Yeh check kar lo pehle:"
â”œâ”€   âœ… Opening animation < 300ms
â”œâ”€   âœ… Dark mode CSS variables working
â”œâ”€   âœ… Mobile responsive (tested)
â”œâ”€   âœ… Backend calls working
â”œâ”€   âœ… Error handling present
```

### **AGENT'S FINAL REPLY:**

"Bilkul! Maine 2 issues fix kar diye:

**Performance:** Animation ko hardware-accelerated banaya, useState mein useMemo add kiya. Ab opening time 500ms se 300ms ho gaya.

**Dark Mode:** CSS variables use kiye hain. User ğŸŒ™ button click karega to automatically dark theme apply hoga.

Code upar dikhai hai, bas copy-paste karo aur test karo. Agar aur improve karna ho to batana! ğŸš€"

---

---

## **AGENT #2: FASTAPI AGENT**

### **Command:** `/fastapi-agent`

### **Skills (Roman Urdu):**
- FastAPI 0.104+ framework - Python mein web server banate ho
- Async/await patterns - Non-blocking code likho (ek sath multiple requests chalenge)
- Pydantic v2 validation - Data input validation (kya data sahi hai ya galat)
- Dependency injection - Code reuse ke liye dependencies share karna
- CORS middleware - Frontend ko backend se data lene ki permission
- Error handling - 404, 500, validation errors handle karna
- Structured logging - Kya kya ho raha hai track karna (logs mein)

### **PRACTICAL USE CASE:**

**User Query:** "Bhai, mara API timeout ho raha hai kabhi kabhi aur 500 error arha hai. Kya kara?"

### **Step-by-Step Process:**

```
STEP 1: USER QUERY
â”œâ”€ User: "FastAPI backend mein kharab lag raha hai, timeout hota hai"

STEP 2: AGENT ACTIVATION
â”œâ”€ /fastapi-agent activate ho jaata hai

STEP 3: ISSUE DIAGNOSIS
â”œâ”€ Agent: "Thik hai, main analyze karta hoon:"
â”œâ”€ Agent: "500 errors usually 3 chezo se aate hain:"
â”œâ”€   1. Database query slow ho
â”œâ”€   2. OpenAI API call hanging ho
â”œâ”€   3. Vector search timeout ho

STEP 4: CODE REVIEW
â”œâ”€ Agent: "Mujhe aapka app/main.py aur services/ dikha rahe ho"
â”œâ”€ Agent: "Dekha! Problem yeh hai:"
â”œâ”€   - RAG service mein no timeout set hai
â”œâ”€   - Database queries optimized nahi hain
â”œâ”€   - Error handling incomplete hai

STEP 5: SOLUTIONS PROVIDE
â”œâ”€ Agent: "Maine 3 fixes identify kiye:"
â”œâ”€   1. Timeouts add karna (FastAPI level)
â”œâ”€   2. Database queries optimize karna
â”œâ”€   3. Better error handling add karna

STEP 6: CODE EXAMPLE - TIMEOUT FIX
â”œâ”€ Agent: "Yeh raha app/main.py update:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ from fastapi import FastAPI, Request
â”œâ”€ from contextlib import asynccontextmanager
â”œâ”€ import asyncio
â”œâ”€
â”œâ”€ # Timeout manager
â”œâ”€ @asynccontextmanager
â”œâ”€ async def lifespan(app: FastAPI):
â”œâ”€     yield
â”œâ”€     # Cleanup code if needed
â”œâ”€
â”œâ”€ app = FastAPI(lifespan=lifespan)
â”œâ”€
â”œâ”€ @app.post("/api/v1/chat")
â”œâ”€ async def chat(request: ChatRequest):
â”œâ”€     try:
â”œâ”€         # 10 second timeout set karo
â”œâ”€         result = await asyncio.wait_for(
â”œâ”€             rag_service.process_query(request.query),
â”œâ”€             timeout=10.0
â”œâ”€         )
â”œâ”€         return result
â”œâ”€     except asyncio.TimeoutError:
â”œâ”€         return {"error": "Request timeout - try shorter query"}
â”œâ”€ ```

STEP 7: CODE EXAMPLE - OPTIMIZATION
â”œâ”€ Agent: "Database queries optimize karna:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ # app/services/rag_service.py - BEFORE (slow)
â”œâ”€ async def process_query(self, query: str):
â”œâ”€     # Har bar full DB scan
â”œâ”€     chunks = await db.query("SELECT * FROM chunks")
â”œâ”€
â”œâ”€ # AFTER (fast - with indexing)
â”œâ”€ async def process_query(self, query: str):
â”œâ”€     # Vector search mein limiting
â”œâ”€     query_vector = await self.embedding_service.embed(query)
â”œâ”€
â”œâ”€     results = await self.qdrant.search(
â”œâ”€         vector=query_vector,
â”œâ”€         limit=5,  # Top 5 only
â”œâ”€         score_threshold=0.3  # Low threshold
â”œâ”€     )
â”œâ”€
â”œâ”€     return results  # Direct return, no extra queries
â”œâ”€ ```

STEP 8: LOGGING ADD KARO
â”œâ”€ Agent: "Kya problem hai track karne ke liye logging add karo:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ import logging
â”œâ”€ import time
â”œâ”€
â”œâ”€ logger = logging.getLogger(__name__)
â”œâ”€
â”œâ”€ @app.post("/api/v1/chat")
â”œâ”€ async def chat(request: ChatRequest):
â”œâ”€     start_time = time.time()
â”œâ”€
â”œâ”€     try:
â”œâ”€         logger.info(f"Query received: {request.query}")
â”œâ”€
â”œâ”€         result = await asyncio.wait_for(
â”œâ”€             rag_service.process_query(request.query),
â”œâ”€             timeout=10.0
â”œâ”€         )
â”œâ”€
â”œâ”€         elapsed = time.time() - start_time
â”œâ”€         logger.info(f"Query processed in {elapsed:.2f}s")
â”œâ”€
â”œâ”€         return result
â”œâ”€     except asyncio.TimeoutError:
â”œâ”€         logger.error("Request timeout after 10s")
â”œâ”€         return {"error": "Timeout"}
â”œâ”€ ```

STEP 9: TESTING
â”œâ”€ Agent: "Test karne ke liye ye steps:"
â”œâ”€   1. Local pe backend start karo
â”œâ”€   2. Normal query bhejo (response time dekho)
â”œâ”€   3. Slow query bhejo (timeout test karo)
â”œâ”€   4. Logs check karo terminal mein

STEP 10: MONITORING
â”œâ”€ Agent: "Production mein Render logs check karo:"
â”œâ”€   1. Render dashboard > Logs
â”œâ”€   2. Performance metrics dekho
â”œâ”€   3. Agar still slow ho to database ke queries check karo
```

### **AGENT'S FINAL REPLY:**

"Aha! Maine issue find kar liya:

**Problem 1:** Timeouts nahi the set. OpenAI API kabhi hang ho jaata tha.
**Solution:** FastAPI ke asyncio.wait_for() se 10-second timeout add kiya.

**Problem 2:** Database queries har baar full scan ho rahe the.
**Solution:** Vector search mein limit=5 aur score_threshold set kiya.

**Problem 3:** Error handling nahi tha.
**Solution:** Try-except blocks add kiye aur logging set up kiya.

Ab test karo, response time pata chal jaega logs mein. Agar aur problem ho to bata! ğŸš€"

---

---

## **AGENT #3: QDRANT AGENT**

### **Command:** `/qdrant-agent`

### **Skills (Roman Urdu):**
- Qdrant vector database - Document search ke liye (similarity search)
- Document ingestion - Files ko vectors mein convert karna
- Vector embeddings - 1536-dimensional vectors (OpenAI model se)
- Cosine similarity - Kaunse document similar hain find karna
- Payload management - Extra metadata store karna (chapter name, week, etc)
- Collection management - Database structure create/manage karna
- Score filtering - Confidence threshold set karna (relevant results filter karna)

### **PRACTICAL USE CASE:**

**User Query:** "Yaar, search results bilkul galat aarhe. User ne 'ROS 2 nodes' poochha to humanoid robotics ka answer arha hai"

### **Step-by-Step Process:**

```
STEP 1: USER QUERY
â”œâ”€ User: "Search results wrong hain, irrelevant documents aa rahe hain"

STEP 2: AGENT ACTIVATION
â”œâ”€ /qdrant-agent activate ho jaata hai

STEP 3: ISSUE DIAGNOSIS
â”œâ”€ Agent: "Search results galat aane ke reasons:"
â”œâ”€   1. Embeddings galat generated ho rahe hain
â”œâ”€   2. Confidence threshold galat set hai
â”œâ”€   3. Documents properly indexed nahi hain

STEP 4: VECTOR DB CHECK
â”œâ”€ Agent: "Qdrant collection check kar raha hoon:"
â”œâ”€   - Collection name: "physical_ai_docs"
â”œâ”€   - Vector size: 1536 âœ“ (Correct)
â”œâ”€   - Documents: 54 âœ“
â”œâ”€   - BUT: Confidence threshold 0.7 set hai (bahut high!)

STEP 5: ROOT CAUSE FOUND
â”œâ”€ Agent: "Problem mila! MIN_CONFIDENCE_THRESHOLD 0.7 hai"
â”œâ”€ Agent: "Matlab sirf 70% se zyada similar docs dikh rahe hain"
â”œâ”€ Agent: "ROS 2 search karte hue humanoid result 65% similar tha"
â”œâ”€ Agent: "0.7 se kam tha, isliye filter out ho gaya"

STEP 6: SOLUTION - THRESHOLD LOWER KARNA
â”œâ”€ Agent: "Yeh fix karo app/core/config.py mein:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ # BEFORE (too strict)
â”œâ”€ MIN_CONFIDENCE_THRESHOLD: float = 0.7
â”œâ”€
â”œâ”€ # AFTER (better recall)
â”œâ”€ MIN_CONFIDENCE_THRESHOLD: float = 0.3
â”œâ”€ ```

STEP 7: SOLUTION - BETTER FILTERING
â”œâ”€ Agent: "Pehle filter karo, phir sort karo:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ # app/services/qdrant_service.py
â”œâ”€
â”œâ”€ async def search(self, query_vector, limit, score_threshold):
â”œâ”€     results = await self.client.search(
â”œâ”€         collection_name="physical_ai_docs",
â”œâ”€         query_vector=query_vector,
â”œâ”€         limit=limit,
â”œâ”€         score_threshold=score_threshold  # Now 0.3
â”œâ”€     )
â”œâ”€
â”œâ”€     # Results automatically sorted by score (highest first)
â”œâ”€     # Top 5 mil jaayenge jo similar hain
â”œâ”€
â”œâ”€     return [
â”œâ”€         {
â”œâ”€             "chapter": hit.payload["chapter"],
â”œâ”€             "content": hit.payload["content"],
â”œâ”€             "score": hit.score,  # 0.95 = 95% similar
â”œâ”€             "week": hit.payload["week"],
â”œâ”€             "module": hit.payload["module"]
â”œâ”€         }
â”œâ”€         for hit in results
â”œâ”€     ]
â”œâ”€ ```

STEP 8: CHECK INGESTION
â”œâ”€ Agent: "Dekho collection mein sab documents sahi hain ya nahi:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ # Run this to check
â”œâ”€ async def check_collection():
â”œâ”€     collection = await qdrant.get_collection("physical_ai_docs")
â”œâ”€     print(f"Total vectors: {collection.points_count}")
â”œâ”€     print(f"Vector size: {collection.config.params.vectors.size}")
â”œâ”€
â”œâ”€     # Sample queries test karo
â”œâ”€     test_query = "ROS 2 nodes"
â”œâ”€     embedding = await embedding_service.embed(test_query)
â”œâ”€     results = await qdrant.search(
â”œâ”€         collection_name="physical_ai_docs",
â”œâ”€         query_vector=embedding,
â”œâ”€         limit=5,
â”œâ”€         score_threshold=0.3
â”œâ”€     )
â”œâ”€
â”œâ”€     for hit in results:
â”œâ”€         print(f"{hit.payload['chapter']}: {hit.score:.2f}")
â”œâ”€ ```

STEP 9: DEBUGGING
â”œâ”€ Agent: "Agar aur bhi specific results chahiye:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ # Filter by module
â”œâ”€ results = await qdrant.search(
â”œâ”€     collection_name="physical_ai_docs",
â”œâ”€     query_vector=query_embedding,
â”œâ”€     query_filter=Filter(
â”œâ”€         must=[
â”œâ”€             FieldCondition(
â”œâ”€                 key="module",
â”œâ”€                 match=MatchValue(value=1)  # Module 1 only
â”œâ”€             )
â”œâ”€         ]
â”œâ”€     ),
â”œâ”€     limit=5,
â”œâ”€     score_threshold=0.3
â”œâ”€ )
â”œâ”€ ```

STEP 10: VALIDATION
â”œâ”€ Agent: "Test karo yeh queries:"
â”œâ”€   1. "ROS 2 nodes" â†’ Should get ros2-fundamentals (0.95+)
â”œâ”€   2. "Digital twins" â†’ Should get digital-twins.md (0.90+)
â”œâ”€   3. "Isaac Sim" â†’ Should get nvidia-isaac-sim.md (0.88+)
â”œâ”€   4. "Random words xyz" â†’ Should get fallback (0.25-0.35)
```

### **AGENT'S FINAL REPLY:**

"Bilkul! Issue pata chal gaya:

**Problem:** MIN_CONFIDENCE_THRESHOLD 0.7 set tha (70% similarity chahiye)
ROS 2 ke relevant results 0.65-0.68 score par tha, filter out ho rahe the.

**Fix:** Threshold 0.7 se 0.3 kiya (30% minimum)
Ab 'ROS 2 nodes' query ke liye top 5 relevant results aayenge.

**Update karo:**
- `app/core/config.py`: MIN_CONFIDENCE_THRESHOLD = 0.3
- Backend restart karo
- Test query bhejo

Ab sahi results ayenge! ğŸ¯"

---

---

## **AGENT #4: OPENAI AGENT**

### **Command:** `/openai-agent`

### **Skills (Roman Urdu):**
- OpenAI API integration - API calls karna
- text-embedding-3-small model - Text ko 1536-dimensional vectors mein convert karna
- gpt-4o-mini model - Fast aur cheap ChatGPT API
- System prompt engineering - AI ko instructions dena (kya batana hai, kaise batana hai)
- Context injection - Search results ko prompt mein add karna
- Token management - Cost control (tokens consumption track karna)
- Rate limiting - API limits within rehna
- Error handling - API failures handle karna

### **PRACTICAL USE CASE:**

**User Query:** "Chatbot sirf 'I'm sorry' reply de raha hai. Proper answer nahi de raha aur confidence bhi nahi hai"

### **Step-by-Step Process:**

```
STEP 1: USER QUERY
â”œâ”€ User: "Chatbot ka response bilkul galat hai, har query pe 'I'm sorry' arha hai"

STEP 2: AGENT ACTIVATION
â”œâ”€ /openai-agent activate ho jaata hai

STEP 3: ISSUE DIAGNOSIS
â”œâ”€ Agent: "This happens when:"
â”œâ”€   1. System prompt apologie karta hai
â”œâ”€   2. Context nahi milta (vector search fail)
â”œâ”€   3. API response khrab hai
â”œâ”€   4. Confidence low hai

STEP 4: SYSTEM PROMPT CHECK
â”œâ”€ Agent: "Aapka system prompt dekh raha hoon"
â”œâ”€ Agent: "AHA! Problem mila:"
â”œâ”€
â”œâ”€ CURRENT (WRONG):
â”œâ”€ "If you don't have relevant information, apologize and say sorry..."
â”œâ”€
â”œâ”€ CHANGE TO:
â”œâ”€ "Answer confidently based on the course content..."

STEP 5: CONTEXT ISSUE
â”œâ”€ Agent: "Agar vector search empty aye, to fallback mode chalani chahiye"
â”œâ”€ Agent: "Aapka RAG pipeline:"
â”œâ”€   1. Query embedding generate karta hai
â”œâ”€   2. Qdrant search karta hai
â”œâ”€   3. Agar 0 results: "I'm sorry" message deta hai
â”œâ”€   4. GALAT! Should give best answer from general knowledge

STEP 6: UPDATED SYSTEM PROMPT
â”œâ”€ Agent: "Yeh raha fixed system prompt:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ # app/services/chat_service.py
â”œâ”€
â”œâ”€ def _create_system_prompt(self, context: str) -> str:
â”œâ”€     return f"""You are an expert Physical AI teaching assistant.
â”œâ”€
â”œâ”€ **Your Task**: Answer student questions confidently.
â”œâ”€
â”œâ”€ **Guidelines**:
â”œâ”€ 1. Answer DIRECTLY using the context below
â”œâ”€ 2. Explain concepts clearly
â”œâ”€ 3. Use examples from context when available
â”œâ”€ 4. **DO NOT apologize** - provide helpful answers
â”œâ”€ 5. If context limited, use your knowledge of the topic
â”œâ”€
â”œâ”€ **Course Content:**
â”œâ”€ {context}
â”œâ”€
â”œâ”€ Answer the question clearly and helpfully."""
â”œâ”€ ```

STEP 7: RAG SERVICE UPDATE
â”œâ”€ Agent: "RAG pipeline mein fallback mode add karo:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ # app/services/rag_service.py
â”œâ”€
â”œâ”€ async def process_query(self, query: str):
â”œâ”€     # Step 1: Try vector search
â”œâ”€     search_results = []
â”œâ”€     context = ""
â”œâ”€
â”œâ”€     try:
â”œâ”€         query_embedding = await self.embedding_service.embed(query)
â”œâ”€         search_results = await self.qdrant.search(
â”œâ”€             query_vector=query_embedding,
â”œâ”€             limit=5,
â”œâ”€             score_threshold=0.3
â”œâ”€         )
â”œâ”€
â”œâ”€         context = "\n\n".join([
â”œâ”€             f"[{r['chapter']}]\n{r['content']}"
â”œâ”€             for r in search_results
â”œâ”€         ])
â”œâ”€     except Exception as e:
â”œâ”€         logger.warning(f"Search failed: {e}")
â”œâ”€         context = ""  # Empty context, no apology!
â”œâ”€
â”œâ”€     # Step 2: Generate response (with or without context)
â”œâ”€     answer = await self.chat_service.generate_response(
â”œâ”€         query=query,
â”œâ”€         context=context
â”œâ”€     )
â”œâ”€
â”œâ”€     # Step 3: Calculate confidence
â”œâ”€     confidence = max([r["score"] for r in search_results]) if search_results else 0.5
â”œâ”€
â”œâ”€     return {
â”œâ”€         "answer": answer,
â”œâ”€         "sources": [{"chapter": r["chapter"], "score": r["score"]} for r in search_results],
â”œâ”€         "confidence": confidence
â”œâ”€     }
â”œâ”€ ```

STEP 8: TOKEN OPTIMIZATION
â”œâ”€ Agent: "OpenAI API cost control:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ import tiktoken
â”œâ”€
â”œâ”€ def count_tokens(text: str) -> int:
â”œâ”€     encoding = tiktoken.encoding_for_model("gpt-4o-mini")
â”œâ”€     return len(encoding.encode(text))
â”œâ”€
â”œâ”€ # Agar context bahut bada hai to trim karo
â”œâ”€ if count_tokens(context) > 1000:
â”œâ”€     context = context[:1000] + "..."
â”œâ”€ ```

STEP 9: ERROR HANDLING
â”œâ”€ Agent: "API failures handle karo:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ try:
â”œâ”€     response = await self.client.chat.completions.create(
â”œâ”€         model="gpt-4o-mini",
â”œâ”€         messages=[...],
â”œâ”€         timeout=10.0
â”œâ”€     )
â”œâ”€ except openai.RateLimitError:
â”œâ”€     return "API rate limit exceeded, try again later"
â”œâ”€ except openai.APIError as e:
â”œâ”€     logger.error(f"OpenAI error: {e}")
â”œâ”€     return "Service temporarily unavailable"
â”œâ”€ ```

STEP 10: TESTING
â”œâ”€ Agent: "Test these scenarios:"
â”œâ”€   1. Normal query with good context â†’ Should give confident answer
â”œâ”€   2. Query with bad context â†’ Should still answer, but low confidence
â”œâ”€   3. Nonsense query â†’ Should give best effort answer
â”œâ”€   4. API failure â†’ Should handle gracefully
```

### **AGENT'S FINAL REPLY:**

"Bilkul samajh agaya!

**Problem 1:** System prompt apologetic tha
**Fix:** System prompt change kiya, ab confident answer dega

**Problem 2:** Empty context aye to 'I'm sorry' deta tha
**Fix:** Fallback mode add kiya, general knowledge use karega

**Problem 3:** Token optimization nahi tha
**Fix:** tiktoken se token counting add ki

**Changes:**
1. Update `app/services/chat_service.py` - system prompt
2. Update `app/services/rag_service.py` - fallback mode
3. Restart backend
4. Test query bhejo

Ab confident aur helpful answers aayenge! ğŸ’ª"

---

---

## **AGENT #5: NEON POSTGRES AGENT**

### **Command:** `/neon-postgres-agent`

### **Skills (Roman Urdu):**
- Neon serverless Postgres - Cloud database (free tier)
- AsyncPG driver - Async database connections (ek sath multiple queries)
- SQLAlchemy 2.0 ORM - Database operations ko Python se manage karna
- Connection pooling - Multiple connections share karna
- Query optimization - Queries ko fast banano
- Schema migrations - Database structure change karna (Alembic se)
- Session management - Chat history save karna

### **PRACTICAL USE CASE:**

**User Query:** "Chat history save nahi ho rahi database mein. User ko pichla conversation nahi dikhta"

### **Step-by-Step Process:**

```
STEP 1: USER QUERY
â”œâ”€ User: "Database mein chat history nahi save ho rahi"

STEP 2: AGENT ACTIVATION
â”œâ”€ /neon-postgres-agent activate ho jaata hai

STEP 3: ISSUE DIAGNOSIS
â”œâ”€ Agent: "Chat history issues usually:"
â”œâ”€   1. Database connection fail
â”œâ”€   2. Schema not created
â”œâ”€   3. SQLAlchemy models galat
â”œâ”€   4. Async operations properly nahi setup

STEP 4: CONNECTION CHECK
â”œâ”€ Agent: "DATABASE_URL check kar raha hoon:"
â”œâ”€ Agent: "Found issue!"
â”œâ”€
â”œâ”€ WRONG: postgresql://...
â”œâ”€ RIGHT: postgresql+asyncpg://...
â”œâ”€
â”œâ”€ Aapne postgresql driver set kiya hai (sync)
â”œâ”€ Zaroor asyncpg (async) chahiye

STEP 5: CONNECTION FIX
â”œâ”€ Agent: "Update .env file:"
â”œâ”€
â”œâ”€ BEFORE:
â”œâ”€ DATABASE_URL=postgresql://user:password@host/db
â”œâ”€
â”œâ”€ AFTER:
â”œâ”€ DATABASE_URL=postgresql+asyncpg://user:password@host/db

STEP 6: SQLALCHEMY MODELS CREATE
â”œâ”€ Agent: "Models banao app/models/chat.py mein:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ from sqlalchemy import Column, String, DateTime, Integer
â”œâ”€ from sqlalchemy.ext.declarative import declarative_base
â”œâ”€ from datetime import datetime
â”œâ”€
â”œâ”€ Base = declarative_base()
â”œâ”€
â”œâ”€ class ChatSession(Base):
â”œâ”€     __tablename__ = "chat_sessions"
â”œâ”€
â”œâ”€     session_id = Column(String, primary_key=True)
â”œâ”€     user_id = Column(String, nullable=True)
â”œâ”€     created_at = Column(DateTime, default=datetime.utcnow)
â”œâ”€     updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
â”œâ”€
â”œâ”€ class ChatMessage(Base):
â”œâ”€     __tablename__ = "chat_messages"
â”œâ”€
â”œâ”€     id = Column(Integer, primary_key=True)
â”œâ”€     session_id = Column(String, nullable=False)
â”œâ”€     role = Column(String)  # 'user' or 'assistant'
â”œâ”€     content = Column(String)
â”œâ”€     confidence = Column(float, nullable=True)
â”œâ”€     created_at = Column(DateTime, default=datetime.utcnow)
â”œâ”€ ```

STEP 7: DATABASE SERVICE
â”œâ”€ Agent: "Service layer banao app/services/database_service.py:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession
â”œâ”€ from app.models.chat import ChatSession, ChatMessage
â”œâ”€
â”œâ”€ engine = create_async_engine(
â”œâ”€     settings.DATABASE_URL,
â”œâ”€     echo=False,
â”œâ”€     pool_size=5,  # Connection pooling
â”œâ”€     max_overflow=10
â”œâ”€ )
â”œâ”€
â”œâ”€ async def save_message(session_id: str, role: str, content: str):
â”œâ”€     async with AsyncSession(engine) as session:
â”œâ”€         # Pehle session check karo, nahi to create karo
â”œâ”€         existing = await session.execute(
â”œâ”€             select(ChatSession).where(ChatSession.session_id == session_id)
â”œâ”€         )
â”œâ”€         if not existing.scalar():
â”œâ”€             session.add(ChatSession(session_id=session_id))
â”œâ”€             await session.commit()
â”œâ”€
â”œâ”€         # Message save karo
â”œâ”€         message = ChatMessage(
â”œâ”€             session_id=session_id,
â”œâ”€             role=role,
â”œâ”€             content=content
â”œâ”€         )
â”œâ”€         session.add(message)
â”œâ”€         await session.commit()
â”œâ”€
â”œâ”€ async def get_history(session_id: str):
â”œâ”€     async with AsyncSession(engine) as session:
â”œâ”€         result = await session.execute(
â”œâ”€             select(ChatMessage)
â”œâ”€             .where(ChatMessage.session_id == session_id)
â”œâ”€             .order_by(ChatMessage.created_at)
â”œâ”€         )
â”œâ”€         return result.scalars().all()
â”œâ”€ ```

STEP 8: ALEMBIC MIGRATIONS
â”œâ”€ Agent: "Database schema create karo:"
â”œâ”€
â”œâ”€ ```bash
â”œâ”€ # Alembic init karo (agar nahi kiya)
â”œâ”€ alembic init alembic
â”œâ”€
â”œâ”€ # Migration generate karo
â”œâ”€ alembic revision --autogenerate -m "Add chat tables"
â”œâ”€
â”œâ”€ # Apply migration
â”œâ”€ alembic upgrade head
â”œâ”€ ```

STEP 9: CHAT ENDPOINT UPDATE
â”œâ”€ Agent: "Chat endpoint mein history save karo:"
â”œâ”€
â”œâ”€ ```python
â”œâ”€ @router.post("/api/v1/chat")
â”œâ”€ async def chat(request: ChatRequest, db_service: DatabaseService):
â”œâ”€     # Save user message
â”œâ”€     await db_service.save_message(
â”œâ”€         session_id=request.session_id,
â”œâ”€         role="user",
â”œâ”€         content=request.query
â”œâ”€     )
â”œâ”€
â”œâ”€     # Get response
â”œâ”€     result = await rag_service.process_query(request.query)
â”œâ”€
â”œâ”€     # Save assistant message
â”œâ”€     await db_service.save_message(
â”œâ”€         session_id=request.session_id,
â”œâ”€         role="assistant",
â”œâ”€         content=result["answer"]
â”œâ”€     )
â”œâ”€
â”œâ”€     return result
â”œâ”€ ```

STEP 10: TESTING
â”œâ”€ Agent: "Test karo yeh steps:"
â”œâ”€   1. Backend restart karo
â”œâ”€   2. Query bhejo (message save hona chahiye)
â”œâ”€   3. Neon dashboard check karo (chat_messages table mein entry dekho)
â”œâ”€   4. Same session_id se phir query bhejo (history show kare)
```

### **AGENT'S FINAL REPLY:**

"Bilkul! Chat history issue fix:

**Problem 1:** DATABASE_URL mein postgresql use tha (sync driver)
**Fix:** postgresql+asyncpg se change kiya (async)

**Problem 2:** Database tables nahi the
**Fix:** SQLAlchemy models create kiye (ChatSession, ChatMessage)

**Problem 3:** Save logic nahi tha
**Fix:** Database service banaya aur chat endpoint mein integrate kiya

**Steps to implement:**
1. Update .env: DATABASE_URL=postgresql+asyncpg://...
2. Create models (app/models/chat.py)
3. Create database service (app/services/database_service.py)
4. Setup Alembic migrations
5. Restart backend
6. Test query - history save hona chahiye

Ab chat history properly save hogi! ğŸ“"

---

---

# ğŸŸ¢ GROUP 2: SPECKIT PLUS WORKFLOW AGENTS (11)

---

## **AGENT #6: /sp.specify**

### **Purpose:** Feature specification banao

### **PRACTICAL USE CASE:**

**User Query:** "Mujha ek new feature specification chahiye: 'User feedback system' banao"

### **Step-by-Step Process:**

```
STEP 1: USER REQUEST
â”œâ”€ User: "/sp.specify - User feedback system banao"

STEP 2: AGENT ACTIVATION
â”œâ”€ /sp.specify command activate ho jaata hai

STEP 3: REQUIREMENTS GATHERING
â”œâ”€ Agent: "Thik hai, maine 5 targeted clarification questions poocha:"
â”œâ”€
â”œâ”€ Q1: "Feedback kaun collect karega? (Students, Admins, Both?)"
â”œâ”€ Q2: "Feedback kaun kaun sa fields hoga? (Rating, Text, Category?)"
â”œâ”€ Q3: "Database mein long-term rakha jayega ya delete hoga?"
â”œâ”€ Q4: "Real-time notification chahiye feedback par?"
â”œâ”€ Q5: "Analytics dashboard bhe chahiye?"

STEP 4: USER ANSWERS
â”œâ”€ User: "Students se feedback, 5-star rating + comment, store forever, no notification, yes analytics"

STEP 5: SPECIFICATION DOCUMENT GENERATE
â”œâ”€ Agent: "Ab full specification banata hoon..."
â”œâ”€
â”œâ”€ Output file: specs/feedback-system/spec.md
â”œâ”€
â”œâ”€ Content:
â”œâ”€ â”œâ”€ Feature Overview
â”œâ”€ â”œâ”€ User Stories
â”œâ”€ â”‚  â”œâ”€ US1: Student submit feedback
â”œâ”€ â”‚  â”œâ”€ US2: Admin view analytics
â”œâ”€ â”‚  â””â”€ US3: Generate reports
â”œâ”€ â”œâ”€ Functional Requirements (FR-001 to FR-010)
â”œâ”€ â”œâ”€ Non-Functional Requirements
â”œâ”€ â”œâ”€ Success Criteria (SC-001 to SC-008)
â”œâ”€ â”œâ”€ Data Models
â”œâ”€ â””â”€ Test Cases

STEP 6: SUCCESS METRICS
â”œâ”€ Agent: "Success ko measure karega in se:"
â”œâ”€   âœ… 95% feedback submission success rate
â”œâ”€   âœ… Analytics dashboard loads in < 2s
â”œâ”€   âœ… 5-star rating system working
â”œâ”€   âœ… Comments searchable

STEP 7: OUTPUT
â”œâ”€ Agent creates:
â”œâ”€   1. specs/feedback-system/spec.md (200+ lines)
â”œâ”€   2. Creates feature branch: feedback-system
â”œâ”€   3. Validates against constitution
```

### **AGENT'S FINAL REPLY:**

"âœ… Specification tiyar ho gaya!

**File:** specs/feedback-system/spec.md
**Branch:** feedback-system (created)

**Contains:**
- 3 User Stories
- 10 Functional Requirements
- 8 Success Criteria
- Data models
- Test cases

Next step: `/sp.plan` chalao implementation plan ke liye! ğŸ“‹"

---

## **AGENT #7: /sp.clarify**

### **Purpose:** Ambiguous requirements ko clear karo

### **PRACTICAL USE CASE:**

**User Query:** "/sp.clarify - Spec mein confusion hai"

### **Step-by-Step Process:**

```
STEP 1: USER REQUEST
â”œâ”€ User: "Kuch points samjha nahi aaye specification mein"

STEP 2: ANALYSIS
â”œâ”€ Agent: Spec.md padhta hai
â”œâ”€ Agent: Ambiguous sections find karta hai

STEP 3: TARGETED QUESTIONS (Max 5)
â”œâ”€ Agent: "Yeh 5 points unclear hain, clarify karo:"
â”œâ”€
â”œâ”€ Q1: "Authentication - JWT ya Session?"
â”œâ”€ Q2: "Rate limiting - Per user ya global?"
â”œâ”€ Q3: "Pagination - Limit kitna hona chahiye?"
â”œâ”€ Q4: "Error responses - Standard format?"
â”œâ”€ Q5: "Caching - Redis ya In-memory?"

STEP 4: USER ANSWERS
â”œâ”€ User: [Answers provide karta hai]

STEP 5: SPEC UPDATE
â”œâ”€ Agent: Updated spec.md ko save karta hai
â”œâ”€ Agent: Ambiguities resolve ho jaate hain
```

### **AGENT'S FINAL REPLY:**

"âœ… Specification clarified!

**Updated file:** specs/feedback-system/spec.md
**Changes:** 5 sections clarified

Ready for planning? Run `/sp.plan` next! ğŸš€"

---

## **AGENT #8: /sp.plan**

### **Purpose:** Implementation plan banao

### **PRACTICAL USE CASE:**

**User Query:** "/sp.plan - Ab plan banao"

### **Step-by-Step Process:**

```
STEP 1: PLAN GENERATION
â”œâ”€ Agent: Spec.md padhta hai
â”œâ”€ Agent: Architecture design karta hai

STEP 2: ARCHITECTURAL DECISIONS
â”œâ”€ Agent identifies:
â”œâ”€   1. Database choice (Neon Postgres)
â”œâ”€   2. API design (RESTful)
â”œâ”€   3. Frontend framework (React)
â”œâ”€   4. Caching strategy (Redis)
â”œâ”€   5. Security approach (JWT + CORS)

STEP 3: COMPONENT ARCHITECTURE
â”œâ”€ Frontend Components
â”œâ”€ Backend Services
â”œâ”€ Database Schema
â”œâ”€ API Endpoints

STEP 4: BUILD PIPELINE
â”œâ”€ Build steps
â”œâ”€ Deployment strategy
â”œâ”€ Testing approach

STEP 5: OUTPUT FILES
â”œâ”€ specs/feedback-system/plan.md (400+ lines)
â”œâ”€ specs/feedback-system/data-model.md
â”œâ”€ specs/feedback-system/research.md
```

### **AGENT'S FINAL REPLY:**

"âœ… Implementation plan ready!

**Files:**
- specs/feedback-system/plan.md
- specs/feedback-system/data-model.md
- specs/feedback-system/research.md

**Key Decisions Documented:**
- Neon Postgres for storage
- Redis for caching
- JWT authentication

Next: `/sp.tasks` - break into granular tasks! ğŸ“"

---

## **AGENT #9: /sp.adr <title>**

### **Purpose:** Major architectural decisions document karo

### **PRACTICAL USE CASE:**

**User Query:** "/sp.adr Use Qdrant instead of Pinecone for vector search"

### **Step-by-Step Process:**

```
STEP 1: DECISION IDENTIFICATION
â”œâ”€ User: "/sp.adr Use Qdrant instead of Pinecone"

STEP 2: ADR DOCUMENT CREATION
â”œâ”€ Agent creates: history/adr/001-vector-db-choice.md
â”œâ”€
â”œâ”€ Content:
â”œâ”€ â”œâ”€ Status: Proposed/Accepted
â”œâ”€ â”œâ”€ Decision: Use Qdrant Cloud
â”œâ”€ â”œâ”€ Rationale:
â”œâ”€ â”‚  â”œâ”€ 1. Free tier with 5GB storage
â”œâ”€ â”‚  â”œâ”€ 2. Easy integration with Python
â”œâ”€ â”‚  â”œâ”€ 3. Hosted service (no DevOps)
â”œâ”€ â”‚  â”œâ”€ 4. Cost: $0 vs Pinecone $25+/month
â”œâ”€ â”œâ”€ Alternatives Considered:
â”œâ”€ â”‚  â”œâ”€ 1. Pinecone (expensive)
â”œâ”€ â”‚  â”œâ”€ 2. Weaviate (complex)
â”œâ”€ â”‚  â”œâ”€ 3. Self-hosted Qdrant (DevOps overhead)
â”œâ”€ â”œâ”€ Consequences:
â”œâ”€ â”‚  â”œâ”€ Pros: Cost-effective, managed service
â”œâ”€ â”‚  â””â”€ Cons: Rate limits, vendor lock-in
â”œâ”€ â””â”€ Date: 2024-12-13

STEP 3: VALIDATION
â”œâ”€ Agent: ADR validate karta hai
â”œâ”€ Agent: Confirm karta hai ye decision significant hai
```

### **AGENT'S FINAL REPLY:**

"âœ… ADR documented!

**File:** history/adr/001-vector-db-choice.md
**Decision:** Use Qdrant Cloud (vs Pinecone)
**Status:** Accepted

**Rationale:** Free tier + easy integration + no DevOps overhead

Reference this when discussing database choices! ğŸ“‹"

---

## **AGENT #10: /sp.tasks**

### **Purpose:** Break specification into granular tasks

### **PRACTICAL USE CASE:**

**User Query:** "/sp.tasks - Break down into implementation tasks"

### **Step-by-Step Process:**

```
STEP 1: SPECIFICATION ANALYSIS
â”œâ”€ Agent: spec.md padhta hai
â”œâ”€ Agent: User stories identify karta hai
â”œâ”€ Agent: Components breakdown karta hai

STEP 2: TASK DECOMPOSITION
â”œâ”€ Agent: 75+ tasks generate karta hai
â”œâ”€ Format: T001 [P] [US1] Description with file path
â”œâ”€
â”œâ”€ Example tasks:
â”œâ”€ â”œâ”€ T001 [P] [US1] Create feedback table in Neon
â”œâ”€ â”œâ”€ T002 [P] [US1] Create FeedbackModel in SQLAlchemy
â”œâ”€ â”œâ”€ T003 [US1] Add POST /feedback endpoint
â”œâ”€ â”œâ”€ T004 [P] [US1] Create React FeedbackForm component
â”œâ”€ â”œâ”€ T005 [US1] Integrate form with backend
â”œâ”€ â”œâ”€ T006 [P] [US2] Create analytics dashboard schema
â”œâ”€ â”œâ”€ T007 [US2] Build analytics API endpoint
â”œâ”€ â”œâ”€ T008 [P] [US2] Create analytics frontend component
â”œâ”€ â””â”€ ... (continuing to T075+)

STEP 3: MVP DEFINITION
â”œâ”€ Agent: MVP tasks identify karta hai (T001-T020)
â”œâ”€ These are minimum viable product tasks

STEP 4: PARALLELIZATION
â”œâ”€ Agent: Tasks ko [P] tag karta hai
â”œâ”€ [P] = Parallel execution possible
â”œâ”€ 50+ tasks parallel ho sakte hain

STEP 5: OUTPUT
â”œâ”€ File: specs/feedback-system/tasks.md
â”œâ”€ Contains: 75+ tasks, fully organized
```

### **AGENT'S FINAL REPLY:**

"âœ… Tasks generated!

**File:** specs/feedback-system/tasks.md
**Total Tasks:** 78
**MVP Tasks:** T001-T020 (13 days)
**Full Implementation:** T001-T078 (30 days)
**Parallel Tasks:** 45 ([P] marked)

Ready to implement? Run `/sp.implement T001-T010` to start! ğŸš€"

---

## **AGENT #11: /sp.checklist**

### **Purpose:** Validation checklist generate karo

### **PRACTICAL USE CASE:**

**User Query:** "/sp.checklist - Generate validation checklist"

### **Step-by-Step Process:**

```
STEP 1: SPECIFICATION REVIEW
â”œâ”€ Agent: spec.md padhta hai

STEP 2: CHECKLIST ITEMS GENERATE
â”œâ”€ Agent creates:
â”œâ”€ â”œâ”€ Functional Requirements Checklist (10 items)
â”œâ”€ â”œâ”€ Non-Functional Checklist (8 items)
â”œâ”€ â”œâ”€ UI/UX Checklist (12 items)
â”œâ”€ â”œâ”€ Performance Checklist (6 items)
â”œâ”€ â”œâ”€ Security Checklist (8 items)
â”œâ”€ â”œâ”€ Testing Checklist (15 items)
â”œâ”€ â””â”€ Deployment Checklist (10 items)

STEP 3: OUTPUT
â”œâ”€ File: specs/feedback-system/checklist.md
â”œâ”€ Format: Markdown checklist items
â”œâ”€   - [ ] Item 1
â”œâ”€   - [ ] Item 2
â”œâ”€   etc.
```

### **AGENT'S FINAL REPLY:**

"âœ… Validation checklist ready!

**File:** specs/feedback-system/checklist.md
**Total Items:** 69
**Categories:** 7

Use this checklist during development to verify requirements! âœ“"

---

## **AGENT #12: /sp.analyze**

### **Purpose:** Spec â†’ Plan â†’ Tasks alignment check karo

### **PRACTICAL USE CASE:**

**User Query:** "/sp.analyze - Check consistency between all docs"

### **Step-by-Step Process:**

```
STEP 1: CROSS-ARTIFACT ANALYSIS
â”œâ”€ Agent: spec.md padhta hai
â”œâ”€ Agent: plan.md padhta hai
â”œâ”€ Agent: tasks.md padhta hai

STEP 2: CONSISTENCY CHECK
â”œâ”€ Agent checks:
â”œâ”€   1. Spec mein jo user stories hain, plan mein ho?
â”œâ”€   2. Plan mein jo components hain, tasks mein ho?
â”œâ”€   3. Spec mein success criteria, checklist mein ho?
â”œâ”€   4. Timeframes realistic hain?

STEP 3: REPORT GENERATION
â”œâ”€ Output: Consistency report
â”œâ”€ â”œâ”€ âœ… Alignment: 100%
â”œâ”€ â”œâ”€ âœ… Coverage: All requirements covered
â”œâ”€ â”œâ”€ âœ… No orphaned tasks
â”œâ”€ â””â”€ âš ï¸ Warnings (if any)
```

### **AGENT'S FINAL REPLY:**

"âœ… Consistency analysis complete!

**Status:** All artifacts aligned
**Spec to Plan:** 100% coverage
**Plan to Tasks:** 100% coverage
**Estimated Effort:** 30 days

Ready to implement! ğŸš€"

---

## **AGENT #13: /sp.implement**

### **Purpose:** Execute tasks from tasks.md

### **PRACTICAL USE CASE:**

**User Query:** "/sp.implement - Start with T001-T010"

### **Step-by-Step Process:**

```
STEP 1: TASK READING
â”œâ”€ Agent: tasks.md padhta hai
â”œâ”€ Agent: T001-T010 identify karta hai

STEP 2: EXECUTION
â”œâ”€ Agent: Har task ko in order execute karta hai
â”œâ”€ T001: Create database table
â”œâ”€   â”œâ”€ Read spec.md
â”œâ”€   â”œâ”€ Create SQL migration
â”œâ”€   â”œâ”€ Run migration
â”œâ”€   â””â”€ Verify in database
â”œâ”€
â”œâ”€ T002: Create SQLAlchemy model
â”œâ”€   â”œâ”€ Create models/feedback.py
â”œâ”€   â”œâ”€ Define schema
â”œâ”€   â””â”€ Test import
â”œâ”€
â”œâ”€ ... (continuing for T003-T010)

STEP 3: CODE CHANGES
â”œâ”€ Agent: Code files create/modify karta hai
â”œâ”€ Agent: Each change committed hota hai

STEP 4: PROGRESS TRACKING
â”œâ”€ Agent: tasks.md update karta hai
â”œâ”€ Format: - [x] T001 (completed) or - [ ] T001 (pending)
```

### **AGENT'S FINAL REPLY:**

"âœ… Tasks T001-T010 completed!

**Files created:**
- chatbot-backend/app/models/feedback.py
- chatbot-backend/app/services/feedback_service.py
- chatbot-backend/app/routers/feedback.py
- physical-ai-textbook/src/components/FeedbackForm.tsx

**Database:**
- Neon: 2 new tables created
- Migrations: Applied

**Next:** Run `/sp.implement T011-T020` to continue! ğŸš€"

---

## **AGENT #14: /sp.constitution**

### **Purpose:** Project principles/constitution create/update karo

### **PRACTICAL USE CASE:**

**User Query:** "/sp.constitution - Update project principles"

### **Step-by-Step Process:**

```
STEP 1: PRINCIPLES DEFINITION
â”œâ”€ Agent: Current constitution padhta hai
â”œâ”€ Agent: Updates needed identify karta hai

STEP 2: PRINCIPLES DOCUMENT
â”œâ”€ Output: .specify/memory/constitution.md
â”œâ”€
â”œâ”€ Contains:
â”œâ”€ â”œâ”€ Content Accuracy & Technical Rigor
â”œâ”€ â”œâ”€ Educational Clarity & Accessibility
â”œâ”€ â”œâ”€ Consistency & Standards
â”œâ”€ â”œâ”€ Docusaurus Quality
â”œâ”€ â”œâ”€ Code Example Quality
â”œâ”€ â”œâ”€ UI/UX Excellence
â”œâ”€ â”œâ”€ Deployment & Publishing
â”œâ”€ â””â”€ AI-Driven Content Standards

STEP 3: VALIDATION
â”œâ”€ Agent: Constitution validate karta hai
â”œâ”€ Agent: Ensures it's aligned with project goals
```

### **AGENT'S FINAL REPLY:**

"âœ… Constitution updated!

**File:** .specify/memory/constitution.md
**Principles:** 8 core principles defined

All future work will follow these principles! ğŸ“œ"

---

## **AGENT #15: /sp.phr**

### **Purpose:** Prompt History Record (PHR) create karo

### **PRACTICAL USE CASE:**

**User Query:** "/sp.phr - Document this session"

### **Step-by-Step Process:**

```
STEP 1: PHR METADATA
â”œâ”€ Agent collects:
â”œâ”€   â”œâ”€ PHR ID (auto-generated)
â”œâ”€   â”œâ”€ Title
â”œâ”€   â”œâ”€ Stage (spec/plan/tasks/implement)
â”œâ”€   â”œâ”€ Date & time
â”œâ”€   â”œâ”€ Model used
â”œâ”€   â”œâ”€ Feature name
â”œâ”€   â”œâ”€ Branch name
â”œâ”€   â””â”€ Summary

STEP 2: PROMPT CAPTURE
â”œâ”€ Agent: User prompts capture karta hai
â”œâ”€ Agent: Model responses capture karta hai

STEP 3: FILE CREATION
â”œâ”€ Output: history/prompts/feedback-system/001-feedback-spec.spec.prompt.md
â”œâ”€
â”œâ”€ Contains:
â”œâ”€ â”œâ”€ Metadata section
â”œâ”€ â”œâ”€ User prompt text (full)
â”œâ”€ â”œâ”€ Model response text (full)
â”œâ”€ â””â”€ Artifacts list

STEP 4: STORAGE
â”œâ”€ File stored in: history/prompts/<feature>/<ID>-<slug>.<stage>.prompt.md
```

### **AGENT'S FINAL REPLY:**

"âœ… PHR created and documented!

**File:** history/prompts/feedback-system/001-feedback-spec.spec.prompt.md
**ID:** 001
**Stage:** spec
**Feature:** feedback-system

This session is now permanently recorded for future reference! ğŸ“š"

---

## **AGENT #16: /sp.git.commit_pr**

### **Purpose:** Autonomous git workflow - commit + PR create karo

### **PRACTICAL USE CASE:**

**User Query:** "/sp.git.commit_pr - Commit and create PR"

### **Step-by-Step Process:**

```
STEP 1: GIT STATUS CHECK
â”œâ”€ Agent: Modified files check karta hai
â”œâ”€ Agent: Untracked files check karta hai

STEP 2: COMMIT PREPARATION
â”œâ”€ Agent: Commit message craft karta hai
â”œâ”€ Format:
â”œâ”€ feat: Add feedback system feature
â”œâ”€
â”œâ”€ - Create feedback table in Neon
â”œâ”€ - Add feedback endpoints in FastAPI
â”œâ”€ - Create React form component
â”œâ”€ - Integrate with backend
â”œâ”€ - Add validation & error handling
â”œâ”€
â”œâ”€ ğŸ¤– Generated with Claude Code

STEP 3: GIT OPERATIONS
â”œâ”€ Command 1: git add . (stage all changes)
â”œâ”€ Command 2: git commit -m "..." (commit)
â”œâ”€ Command 3: git push origin feedback-system (push)

STEP 4: PR CREATION
â”œâ”€ Agent: GitHub PR create karta hai
â”œâ”€ Title: "feat: Add feedback system"
â”œâ”€ Body:
â”œâ”€   ## Summary
â”œâ”€   - Complete feedback collection system
â”œâ”€   - Analytics dashboard for admins
â”œâ”€   - Real-time feedback aggregation
â”œâ”€
â”œâ”€   ## Changes
â”œâ”€   - Created feedback tables
â”œâ”€   - Added 12 API endpoints
â”œâ”€   - Built React components
â”œâ”€   - Integrated with backend

STEP 5: OUTPUT
â”œâ”€ Agent returns: PR URL
â”œâ”€ Example: https://github.com/username/repo/pull/23
```

### **AGENT'S FINAL REPLY:**

"âœ… Changes committed and PR created!

**Commit:** 8 files changed, 245 insertions
**Branch:** feedback-system
**PR URL:** https://github.com/naveed261/GIAIC-HACKATON-1_PROJECT-1/pull/23

**Title:** feat: Add complete feedback system
**Description:** Feedback collection + analytics dashboard

PR ready for review! ğŸš€"

---

---

# ğŸ¯ COMPLETE AGENT SUMMARY

## **16 AGENTS TOTAL:**

### **GROUP 1: DOMAIN EXPERTS (5)**
1. âœ… Docusaurus Chatbot Agent - UI/Frontend
2. âœ… FastAPI Agent - Backend API
3. âœ… Qdrant Agent - Vector Database
4. âœ… OpenAI Agent - AI/ML Integration
5. âœ… Neon Postgres Agent - Database Management

### **GROUP 2: WORKFLOW (11)**
6. âœ… /sp.specify - Create specification
7. âœ… /sp.clarify - Ask clarification
8. âœ… /sp.plan - Generate plan
9. âœ… /sp.adr - Architecture decisions
10. âœ… /sp.tasks - Break into tasks
11. âœ… /sp.checklist - Validation checklist
12. âœ… /sp.analyze - Consistency check
13. âœ… /sp.implement - Execute implementation
14. âœ… /sp.constitution - Project principles
15. âœ… /sp.phr - Prompt history record
16. âœ… /sp.git.commit_pr - Git workflow

---

## **KAY REMEMBER KARO:**

**Har agent ek specialist hai!**
- Problem aaye â†’ Right agent call karo
- Agent analyze karega
- Solutions dega
- Code examples dega
- Step-by-step guide dega

**Example:** Agar Qdrant search slow ho to `/qdrant-agent` call karo, bilkul detailed solution milaega!

**Bas yeh samajh lo: 16 Experts = 16 Different Specialized Skills! ğŸ¤–**



 ACTUAL ORCHESTRATION FLOW:

  USER QUERY
      â†“
  CLAUDE CODE (Main Agent)
      â”œâ”€ Query samjhta hai
      â”œâ”€ Decide karta hai: Direct solve or Sub-agent?
      â”‚
      â”œâ”€ Agar direct: Solve karta hai, reply deta hai
      â”‚
      â”œâ”€ Agar complex: Right agent identify karta hai
      â”‚
      â””â”€ Agent ko Task deta hai with context
           â†“
      SUB-AGENT (Specialist)
           â”œâ”€ Task receive karta hai
           â”œâ”€ Problem analyze karta hai
           â”œâ”€ Solution deta hai
           â””â”€ Results Claude Code ko return karta hai
           â†“
      CLAUDE CODE
           â”œâ”€ Results process karta hai
           â”œâ”€ Format karta hai
           â””â”€ USER KO FINAL ANSWER DETA HAI

  ---
  EXAMPLE:

  USER: "Chatbot widget slow hai"
      â†“
  CLAUDE CODE: "Yeh UI problem hai, /docusaurus-chatbot-agent ko bhejta hoon"
      â†“
  AGENT: "Analyzed! Performance issue: useState caching nahi hai. Fix: useMemo add karo"
      â†“
  CLAUDE CODE: Agent ka solution process karta hai, user ko samjha deta hai
      â†“
  USER: "Yeh raha solution - useMemo add kar, animation optimize kar"

  ---
  KEY POINT:

  Claude Code = Orchestrator (conductor)
  - User query receive
  - Right specialist choose
  - Task assign + supervise
  - Final answer deliver

  Agents = Specialists (musicians)
  - Specific task solve
  - Results return
  - Done